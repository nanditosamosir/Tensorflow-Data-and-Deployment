{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started with TensorFlow Serving"
      ],
      "metadata": {
        "id": "EavH3ONJm08E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "l9KTEIK5m5Hq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFcrL14GmzVH",
        "outputId": "67551322-0c16-45f6-d4a5-8b9036087f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEwrNK2Zm7A7",
        "outputId": "15ae7143-3b93-4707-a714-3ab6ed4b19a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â€¢ Using TensorFlow Version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add TensorFlow Serving Distribution URL as a Package"
      ],
      "metadata": {
        "id": "5ZqVL5HBnKrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoY07XqCnJ18",
        "outputId": "03364d1f-0ced-49ff-a4e6-80faacb0b579"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "100  2943  100  2943    0     0  18295      0 --:--:-- --:--:-- --:--:-- 18393\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:8 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Get:9 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,373 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,069 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [31.9 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,789 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,308 kB]\n",
            "Fetched 7,916 kB in 2s (3,544 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "48 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mhttp://storage.googleapis.com/tensorflow-serving-apt/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install TensorDlow Serving"
      ],
      "metadata": {
        "id": "g1BuFRRInc4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHu5jvRPna6p",
        "outputId": "f11dc196-f400-4f01-c1d2-d40158bb7029"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 650 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.16.1 [650 MB]\n",
            "Fetched 650 MB in 8s (81.6 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.16.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.16.1) ...\n",
            "Setting up tensorflow-model-server (2.16.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset"
      ],
      "metadata": {
        "id": "VSXcU38dni3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "metadata": {
        "id": "7H6GZaXvnhjm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Train the Model"
      ],
      "metadata": {
        "id": "Qt-S2U_6nnbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='mean_squared_error')\n",
        "\n",
        "history = model.fit(xs, ys, epochs=500, verbose=0)\n",
        "\n",
        "print('Finished training the model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXhCVe7nm1O",
        "outputId": "645ed93b-47cc-4a08-8500-7d71cf681ea0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished training the model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Model"
      ],
      "metadata": {
        "id": "tlSMVLRVoNm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.array([10.0])\n",
        "\n",
        "print(model.predict(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhobrcFEn7-J",
        "outputId": "0adfca66-747d-4161-dcbd-315acf25783c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 127ms/step\n",
            "[[18.977203]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Model"
      ],
      "metadata": {
        "id": "wY3h3_8VoWn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "  print('\\nAlready saved a model, cleaning up\\n')\n",
        "  !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format='tf')\n",
        "\n",
        "print('\\nexport_path = {}.'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liZsRSZzoT4J",
        "outputId": "060e90aa-18f3-4086-ec69-6be34aba83d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Already saved a model, cleaning up\n",
            "\n",
            "\n",
            "export_path = /tmp/1.\n",
            "total 60\n",
            "drwxr-xr-x 2 root root  4096 May  9 09:15 assets\n",
            "-rw-r--r-- 1 root root    58 May  9 09:15 fingerprint.pb\n",
            "-rw-r--r-- 1 root root  4444 May  9 09:15 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 39976 May  9 09:15 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 May  9 09:15 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examine Your Saved Model"
      ],
      "metadata": {
        "id": "azfQtl-Lo2E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMdDpxU0oypQ",
        "outputId": "4df07a77-9a3f-40ad-cbe2-7536f46b19ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-09 09:16:24.296153: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-09 09:16:24.296246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-09 09:16:24.299893: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-09 09:16:25.883617: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_1_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_dense_1_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'MergeV2Checkpoints', 'Const', 'Pack', 'MatMul', 'NoOp', 'Select', 'DisableCopyOnRead', 'BiasAdd', 'AssignVariableOp', 'StatefulPartitionedCall', 'StaticRegexFullMatch', 'VarHandleOp', 'Placeholder', 'RestoreV2', 'StringJoin', 'SaveV2', 'Identity', 'ReadVariableOp', 'ShardedFilename'}\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_1_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_1_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_1_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_1_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_1_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_1_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the TensorFlow Model Server"
      ],
      "metadata": {
        "id": "vn3TyFUQo9BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "metadata": {
        "id": "IppOemhOo7Gd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=helloworld \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "metadata": {
        "id": "-mXs6X2LpDX_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail server.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLLPdsrspSin",
        "outputId": "8f191b8a-b866-4d26-c4c7-ba8a1e4a2bb4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 250] NET_LOG: Entering the event loop ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create JSON Object with with Test Data"
      ],
      "metadata": {
        "id": "WKYD9QgrpYPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array([[9.0], [10.0]])\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": xs.tolist()})\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayG71AqxpWKO",
        "outputId": "62bd7b6a-d39a-4b12-b5b9-b4d23b864006"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"signature_name\": \"serving_default\", \"instances\": [[9.0], [10.0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Inference Request"
      ],
      "metadata": {
        "id": "wwW5T96Vprac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if this cell fails execution because of an \"...Failed to establish a new connection...\" error,\n",
        "# try replacing in the link below 'localhost' with '127.0.0.1'\n",
        "\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/helloworld:predict', data=data, headers=headers)\n",
        "\n",
        "print(json_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky3V1TAupnRR",
        "outputId": "1fdb0dd6-5bed-4423-ca6c-b1f4f8350dba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"predictions\": [[16.9805069], [18.9772034]\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = json.loads(json_response.text)['predictions']\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ5jfn8lp_EQ",
        "outputId": "df0078d4-4215-4c5f-8941-05fba09b9ff0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16.9805069], [18.9772034]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MP1phynqGZ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}